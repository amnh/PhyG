Use lens for record-like types
	https://www.fpcomplete.com/haskell/tutorial/lens/
Probably TempleHaskell with lens
	https://wiki.haskell.org/Template_Haskell 
Us FGL for Graph functinoality
Perhpas Pair for Phylogenetic Graph with fgl Gr and a type inclusing char info
(weights, types etc).
	Something like PhyloGraph = (Gr a b, CharInfo c)
	where Charinfo hass charcater info on blocks, weights etc.
Output Graphviz LR ans splines=ortho or line, polyline for more cladofgram look
	{rank=same; A B C D;}   for line up taxa
	can use Bool isGraphVizInstalled for automatic pdf/ps2

References from our conversation regarding PCG FFI usage:

		The FFI pairwise string alignment function is:

		   foreignPairwiseDO
		     :: DenseTransitionCostMatrix -- ^ Structure defining the
		transition costs between character states
		     -> DynamicCharacter          -- ^ First  dynamic character
		     -> DynamicCharacter          -- ^ Second dynamic character
		     -> (Word, DynamicCharacter)

		To be imported from module:
		Analysis.Parsimony.Dynamic.DirectOptimization.Pairwise
		Defined internally in here:
		Analysis.Parsimony.Dynamic.DirectOptimization.Pairwise.FFI

		Saved in the following files, respectively:
		lib/core/analysis/src/Analysis/Parsimony/Dynamic/DirectOptimization/Pairwise.hs
		lib/core/analysis/src/Analysis/Parsimony/Dynamic/DirectOptimization/Pairwise/FFI.hsc



		The tcm for the FFI can be created by the function:

		generateDenseTransitionCostMatrix
		     :: Word                   -- ^ The gap open cost. A zero value
		indicates non-affine alignment context
		     -> Word                   -- ^ The character alphabet size
		     -> (Word -> Word -> Word) -- ^ The function defining the cost to
		transition between two symbols
		     -> DenseTransitionCostMatrix

		To be imported from module: Data.TCM.Dense
		Defined internally in here: Data.TCM.Dense.FFI

		Saved in the following files, respectively:
		 lib/core/tcm/src/Data/TCM/Dense.hs
		 lib/core/tcm/src/Data/TCM/Dense/FFI.hsc



		Dynamic characters can be created by calling the function:

		    encodeStream
		      :: Alphabet a -- This 'a' parameter can be 'Char' or 'String',
		whatever you prefer
		      -> NonEmpty (NonEmpty a)
		      -> DynamicCharacter

		To be imported from module: Bio.Character.Encodable.Dynamic
		Defined internally in here: Bio.Character.Encodable.Stream

		Saved in the following files, respectively:
		 lib/core/tcm/src/Data/TCM/Dense.hs
		 lib/core/tcm/src/Data/TCM/Dense/FFI.hsc



		Alphabet can be constructed by calling the function:

		   fromSymbols
		     :: Ord a
		     => [a]
		     -> Alphabet a

		To be imported from module: Data.Alphabet
		Defined internally in here: Data.Alphabet.Internal

		Saved in the following files, respectively:
		 lib/alphabet/src/Data/Alphabet.hs
		 lib/alphabet/src/Data/Alphabet/Internal.hs



https://hackage.haskell.org/package/fgl-visualize-0.1.0.1/docs/Data-Graph-Inductive-Dot.html
	Perhaps better fgl 2 dot functionality

Prealigned and tcm as optoins in read command that aapply to all fasta/c files
	asopposed to POY "prealigned:"

For documentation:
	Script files '--' for comment to end of line
	one command per line (maybe add ';') for multiple later

Look at hash-graph  library https://github.com/patrickdoc/hash-graph
	some faster and some slower than FGL but strict (think edges and nodes are unlablled)
	

Can use Data hash to get unique bit vector for leaves that is label (and datafile order) invarianty.
    0) Use Naive--bitvector data
	1) sort data
	2) hash data
	3) sort hash, leafe number pairs and assign bits on hash order

Can use graph hash to compare trees or nodes, collpased for multiple graphs etc

Data input
	1) fasta
	2) fastc
	3) TNT
	4) F/E/Newick
	5) Dot
	6) dpead--TNT with spaces for continuous characters (?)

Reports
	Data raw data so can be checked manually 
		csv
		text--pretty print maybe from csv
			https://github.com/lovasko/tablize
			or just replace ',' with '\t' adding line feeds at end of line

	Graphs
		dot
		f/e/newick
		pdfs (?)
	Apomorphy List
	HTU Assignment
		single
		ambiguous
	Pairwise Data
	RF Matrices
	
Data forms
	0) Data structured
		Blocks at top
			Types of chars
			Vectors (or whatever) of word64/BitVector
	1) Raw ShortText for space (not work for search)
	2) Naive BitVectors (works for search)
		Reordered by block
		Not reordered by chartype
		Not purged of contant
	3) Optimized (works for search)
		Characters grouped in "blocks" for display trees 
		Assume each file a block to start
		Need option to change 
		Within blocks Charcaters grouped by type (add, nonadd, sankoff, static, dynamic)
			at first all 64bit or bitvector
				even continuous treat as 64bit number (integerized with weight)
				additive 2x64Bits to keep range
			later recoded with bitpacking types for 2,4,8,16,32, states
			End with groups of same charcaters to reduce logic for optimizations
				Each higher-order character is a vector of 64bit/bitvector
			Join all static with same TCM, 
			if 1:1 make nonAdd
			remove constant chars
			SAnkoff to additive if binary or all same cost (e.g. not gaps and that only difference in tcm)

	4) Transformed data (works for search)
		Implied alignment 
			as recoded static 
			maybe moved to NonAdd
			deletre constant chars
		Turn "off" dynamic

	5) Prealigned seequences -> Approx Matrix/Sankoff 
		Approximate Sankoff type
		Multiple characters with same tcm
		Small Alphabet "dense" extendedTCM
		Large Alphabet Hash extendedTCM
		Transform option between Matrix and ApproxMatrix/Small and Large


Data flow
	1) input data to meta format tuples (name, data, info) 
	2) reconciled data 
		adds in missing etc
		check input graphs leaves agree
	3) reconciled data -> naive data
		naive data all bitvectors (or whatever) 
		naive data can be consumed by all graph etc functions
	4) Naive data -> optimized data
		bit packed, block sorted etc
		used for reporting of graph decorations later
	5) optimized data -> transformed data
		implied alignment
		any other data transform heuristics 
		remove some data and add others


Task groups:
	1) Inputs
		1) Parse input data files
		2) Parse input graphs
		3) Reconcile data and graphs (including laderization)
			Including converting sankoff inputs to additive or non-additive
			Blocks
		4) Convert data to analytical format
           Optimized
        5) Make allowance for recoded data 
            Implied alignment
            GPU

	2) Optimization regemes for two children 
		0) Includes optimality criteria
			1) Parsimony
			2) PhyMDL
		1) Non-additive
			word sizes 2,4,8,16,32,64, big
		2) Additive
		3) Continuous 	
			1) Can create type issues--maybe do some smart stuff to integerize
				find smallest delta between states and normalize on that value
				round states to Int and weight character by normaliation factor
		4) Sankoff
			word sizes 2,4,8,16,32,64, big
			5 for DNA (+gap)? to get 50% more packing versus 8 bits
			21 for aa (+gap)? to get 50% more packing versus 32 bits
		5) Sequence
			alphabet word sizes 2,4,8,16,32,64, big
		6) Distance character?
			for nitial dWag etc on blocks or all

	3) Graph structure
		Vertex and edge types (lenses? prob not too complex)

	4) Graph search routines
		Naive
		Incremental
		Amortized constant
			regular stuff--even if apporximate
			Sankoff shortcuts (Where--in cahracter or graph?)
		Compound 
			Search-like
			Thompson's algorithm

	5) Outputs
		Graphs
			including graph reconciliation
			can can graphviz if installed (there is a call for that)
		Data
			csv of assignments etc
		Append to non-graphical files b y default, overwrite option
		-O for multiple graphs in dot (automatically named with numbers)
		make graph files automatically if dot installed (with better options)?



Test:
	1) Aligned and unaligned amino acid and nucletide (with RNA) data
	2) TNT inputs

	
